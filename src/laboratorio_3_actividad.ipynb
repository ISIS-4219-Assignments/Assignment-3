{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a30e1229feabdfd3",
   "metadata": {},
   "source": [
    "![Machine Learning Lab](banner.jpg)\n",
    "\n",
    "\n",
    "# Laboratorio 3 Actividad\n",
    "\n",
    "\n",
    "## Instrucciones generales\n",
    "\n",
    "\n",
    "1. Esta actividad debe ser entregada por BN y es de carácter individual. No se permite entregar el laboratorio después de la fecha establecida.\n",
    "2. Al responder las preguntas de las actividades por favor marcar las respuestas con la sección a la que corresponden, por ejemplo: `## Exploración de datos 2.1`. Es preferible que esto lo hagan con secciones de MarkDown.\n",
    "3. Por favor nombrar el archivo de acuerdo al siguiente formato `{email}_lab3.ipynb`.\n",
    "4. Si tienen alguna duda pueden escribirme a mi correo `j.rayom@uniandes.edu.co` o contactarme directamente por Teams\n",
    "\n",
    "Para este laboratorio deben usar el siguiente dataset: `https://www.kaggle.com/datasets/vishardmehta/heart-risk-progression-dataset`\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "1. Comprender la estructura y características del dataset mediante la exploración y visualización de datos para identificar patrones relevantes en la predicción en riesgo de ataques al corazón.\n",
    "\n",
    "2. Aplicar técnicas de preprocesamiento y modelado utilizando StandardScaler, OneHotEncoder y SVC, evaluando el impacto de diferentes kernels en la frontera de decisión.\n",
    "\n",
    "3. Optimizar el rendimiento del modelo mediante la búsqueda de hiperparámetros con GridSearchCV.\n",
    "\n",
    "\n",
    "* * *\n",
    "\n",
    "Instrucciones\n",
    "-------------\n",
    "\n",
    "### 0\\. Descarga del Dataset\n",
    "\n",
    "Utiliza el siguiente enlace para descargar el dataset de riesgos cardiovasculares desde Kaggle:\n",
    "\n",
    "[Descargar Dataset](https://www.kaggle.com/datasets/vishardmehta/heart-risk-progression-dataset)\n",
    "\n",
    "El dataset contiene pacientes, donde la columna `risk_category` indica el riesgo de padecer enfermedades cardiovasculares (`Low`, `Medium`, `High`)\n",
    "\n",
    "### 1\\. Exploración de datos (10%)\n",
    "\n",
    "1.  Carga el dataset en un DataFrame de pandas.\n",
    "2.  Elimina las columnas `heart_disease_risk_score` y `Patient_ID`.\n",
    "3.  Realiza un pairplot entre las variables usando seaborne\n",
    "\n",
    "### 2\\. Preprocesamiento de Datos (10%)\n",
    "\n",
    "1.  Separa las características (`X`) de la etiqueta (`Y`). La columna `risk_category` es la etiqueta.\n",
    "3.  Divide el dataset en conjuntos de entrenamiento y prueba utilizando `train_test_split` de `sklearn`. **Asegúrate de usar `random_state=42` para garantizar la reproducibilidad de los resultados.**\n",
    "\n",
    "### 3\\. Exploración efecto del kernel (20%)\n",
    "\n",
    "1. Utilice la función `plot_frontier_svc` definidia abajo para graficar la frontera de decisión entre las clases usando solo las columnas `['systolic_bp', 'age']`. Utilice **`LabelEncoder`** para codificar `Y`. Haga la gráfica para todos los kernels disponibles en sklearn.\n",
    "2. Compare los resultados usando `C = [0.1, 1, 10, 1000]` y `kernel=rbf`. \n",
    "3. Responda las siguientes preguntas\n",
    "\n",
    "- ¿Usando `rbf` que observa sucede a medida que se incrementa `C` con la frontera de decisión?\n",
    "\n",
    "### 4\\. Entrenamiento y Evaluación (30%)\n",
    "\n",
    "1. Construye un pipeline en `sklearn` que incluya los siguientes componentes: **`StandardScaler`**, **`OneHotEncoder`** y **`SVC`**. Utilice la clase `Pipeline` de sklearn y utilice el kernel `poly` con C=`1.0`\n",
    "2. Entrena el modelo con el dataset de entrenamiento\n",
    "3. Producir el reporte completo de clasificación y la matriz de confusión.\n",
    "\n",
    "### 5\\. Optimizacion de parametros (30%)\n",
    "\n",
    "1. Construye un pipeline en `sklearn` que incluya los siguientes componentes: **`StandardScaler`**, **`OneHotEncoder`** y **`SVC`**. Utilice la clase `Pipeline` de sklearn\n",
    "2. Entrena el modelo con el dataset de entrenamiento usando GridSearchCV pruebe todos los kernels disponibles en sklearn y utilice `C = [0.1, 1, 10, 100]`\n",
    "3. Responsa las siguientes preguntas\n",
    "\n",
    "- ¿Cuales hiperparámetros arrojaron el mejor modelo?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e7508d232f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_frontier_svc(X_, y_, kernel=\"linear\", C=1):\n",
    "    \"\"\"\n",
    "    Grafica la frontera de decisión de un clasificador de Máquina de Vectores de Soporte (SVM)\n",
    "    utilizando conjuntos de datos de entrenamiento y prueba.\n",
    "    El clasificador SVM es entrenado en la versión escalada de la matriz de características.\n",
    "    La función visualiza la frontera de decisión.\n",
    "\n",
    "    :param X_: ndarray\n",
    "        La matriz de características. Estos datos deben contener únicamente 2 características,\n",
    "        por ejemplo, ['Glucosa', 'Edad']\n",
    "\n",
    "    :param y_: ndarray\n",
    "        Los valores objetivo/etiquetas de clase correspondientes a las filas de la matriz\n",
    "        de características de entrada.\n",
    "\n",
    "    :param kernel: str, opcional\n",
    "        Especifica el tipo de kernel a utilizar en el algoritmo SVM. Por defecto es \"linear\".\n",
    "        Otras opciones válidas incluyen \"rbf\", \"poly\", \"sigmoid\", etc.\n",
    "\n",
    "    :param C: float, opcional\n",
    "        Parámetro de regularización. La fuerza de la regularización es inversamente\n",
    "        proporcional a C. Valor por defecto es 1.\n",
    "    \"\"\"\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_)\n",
    "\n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(X_scaled, y_, test_size=0.2, random_state=31)\n",
    "\n",
    "    svm = SVC(kernel=kernel, C=C)\n",
    "    svm.fit(X_train_, y_train_)\n",
    "\n",
    "    x_min, x_max = X_scaled[:, 0].min() - 1, X_scaled[:, 0].max() + 1\n",
    "    y_min, y_max = X_scaled[:, 1].min() - 1, X_scaled[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "\n",
    "    Z = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=ListedColormap([\"#ffcccc\", \"#cce5ff\", \"#d4edda\"]))\n",
    "\n",
    "    train_df = pd.DataFrame({\n",
    "        'x': X_train_[:, 0],\n",
    "        'y': X_train_[:, 1],\n",
    "        'class': y_train_,\n",
    "        'set': 'train'\n",
    "    })\n",
    "    test_df = pd.DataFrame({\n",
    "        'x': X_test_[:, 0],\n",
    "        'y': X_test_[:, 1],\n",
    "        'class': y_test_,\n",
    "        'set': 'test'\n",
    "    })\n",
    "    df = pd.concat([train_df, test_df])\n",
    "\n",
    "    sns.scatterplot(data=df, x='x', y='y', hue='class', style='set', palette='tab10' )\n",
    "    plt.xlabel(\"Componente Principal 1\")\n",
    "    plt.ylabel(\"Componente Principal 2\")\n",
    "    plt.title(f\"Frontera de Decisión del SVM kernel: {kernel} C:{C}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
